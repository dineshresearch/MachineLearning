Hilbert space
The mathematical concept of a Hilbert space, named after David Hilbert, generalizes the notion of Euclidean space. It extends the methods of vector algebra from the two-dimensional plane and three-dimensional space to infinite-dimensional spaces. In more formal terms, a Hilbert space is an inner product space — an abstract vector space in which distances and angles can be measured — which is "complete", meaning that if a sequence of vectors is Cauchy, then it converges to some limit in the space.
Hilbert spaces arise naturally and frequently in mathematics, physics, and engineering, typically as infinite-dimensional function spaces. They are indispensable tools in the theories of partial differential equations, quantum mechanics, and signal processing. The recognition of a common algebraic structure within these diverse fields generated a greater conceptual understanding, and the success of Hilbert space methods ushered in a very fruitful era for functional analysis.
Geometric intuition plays an important role in many aspects of Hilbert space theory. An element of a Hilbert space can be uniquely specified by its coordinates with respect to an orthonormal basis, in analogy with Cartesian coordinates in the plane. When that basis is countably infinite, this means that the Hilbert space can also usefully be thought of in terms of infinite sequences that are square-summable. Linear operators on a Hilbert space are likewise fairly concrete objects: in good cases, they are simply transformations that stretch the space by different factors in mutually perpendicular directions.

Ordinary Euclidean space serves as a model for the notion of a Hilbert space. In Euclidean space, denoted R3, the distance between points and the angle between vectors can be expressed via the dot product, an operation on pairs of vectors whose values are real numbers. Problems from analytic geometry, such as determining whether two lines are orthogonal or finding a point on a given plane closest to the origin, can be expressed and then solved using the dot product.[1] Another important feature of R3 is that it possesses enough structure to support the methods of calculus, because of the existence of certain limits. Hilbert spaces are generalizations of R3 which possess an analog of the dot product (usually called an inner product) and are "complete" in the sense that the limits needed to perform calculus exist.
Prior to the development of Hilbert spaces, other generalizations of R3 were known to mathematicians and physicists. In particular, the idea of an abstract linear space had gained some traction towards the end of the 19th century:[citation needed] this is a space whose elements can be added together and multiplied by scalars (such as real or complex numbers) without necessarily identifying these elements with "geometric" vectors, such as position and momentum vectors in physical systems. Other objects studied by mathematicians at the turn of the 20th century, in particular spaces of sequences (including series) and spaces of functions,[2] can naturally be thought of as linear spaces. Functions, for instance, can be added together or multiplied by constant scalars, and these operations obey the algebraic laws satisfied by addition and scalar multiplication of spatial vectors.
In the first decade of the 20th century, parallel developments led to the introduction of Hilbert spaces. The first of these was the observation, which arose during David Hilbert and Erhard Schmidt's study of integral equations,[3] that two square-integrable real-valued functions f and g on an interval [a,b] have an inner product
which has many of the familiar properties of the Euclidean dot product. In particular, the idea of an orthogonal family of functions has meaning. Schmidt exploited the similarity of this inner product with the usual dot product to prove an analog of the spectral decomposition for an operator of the form
where K is a continuous function symmetric in x and y. The resulting eigenfunction expansion expresses the function K as a series of the form
where the functions φn are orthogonal in the sense that 〈φn,φm〉 = 0 for all n ≠ m. However, there are eigenfunction expansions which fail to converge in a suitable sense to a square-integrable function: the missing ingredient, which ensures convergence, is completeness.[4]
The second development was the Lebesgue integral, an alternative to the Riemann integral introduced by Henri Lebesgue in 1904.[5] The Lebesgue integral made it possible to integrate more than just continuous functions. In 1907, Frigyes Riesz and Ernst Sigismund Fischer independently proved that the space L2 of square Lebesgue-integrable functions is complete metric space.[6] As a consequence of the interplay between geometry and completeness, the 19th century results of Joseph Fourier, Friedrich Bessel and Marc-Antoine Parseval on trigonometric series easily carried over to these more general spaces, resulting in a geometrical and analytical apparatus now usually known as the Riesz-Fischer theorem.[7]
Further basic results were proved in the early 20th century. For example, the Riesz representation theorem was independently established by Maurice Fréchet and Frigyes Riesz in 1907.[8] John von Neumann coined the term abstract Hilbert space in his famous work on unbounded Hermitian operators.[9] Von Neumann was perhaps the mathematician who most clearly recognized their importance as a result of his seminal work on the foundations of quantum mechanics,[10] and continued in his work with Eugene Wigner. The name "Hilbert space" was soon adopted by others, for example by Hermann Weyl in his book on quantum mechanics and the theory of groups.[11]
The significance of the concept of a Hilbert space was underlined with the realization that it offers one of the best mathematical formulations of quantum mechanics.[12] In short, the states of a quantum mechanical system are vectors in a certain Hilbert space, the observables are hermitian operators on that space, the symmetries of the system are unitary operators, and measurements are orthogonal projections. The relation between quantum mechanical symmetries and unitary operators provided an impetus for the development of the unitary representation theory of groups, initiated in the 1928 work of Hermann Weyl.[13] On the other hand, in the early 1930s it became clear that certain properties of classical dynamical systems can be analyzed using Hilbert space techniques in the framework of ergodic theory.[14]

Many of the applications of Hilbert spaces exploit the fact that Hilbert spaces support generalizations of simple geometric concepts like projection and change of basis from their usual finite dimensional setting. In particular, the spectral theory of continuous self-adjoint linear operators on a Hilbert space generalizes the usual spectral decomposition of a matrix, and this often plays a major role in applications of the theory to other areas of mathematics and physics.

In the theory of ordinary differential equations, spectral methods on a suitable Hilbert space are used to study the behavior of eigenvalues and eigenfunctions of differential equations. For example, the Sturm–Liouville problem arises in the study of the harmonics of waves in a violin string or a drum.[15] The problem is a differential equation of the form
for an unknown function y on an interval [a,b], satisfying general homogeneous Robin boundary conditions
The functions p, q, and w are given in advance, and the problem is to find the function y and constants λ for which the equation has a solution. The problem only has solutions for certain values of λ, called eigenvalues of the system, and this is a consequence of the spectral theorem for compact operators applied to the integral operator defined by the Green's function for the system. Furthermore, another consequence of this general result is that the eigenvalues λ of the system can be arranged in an increasing sequence tending to infinity.[16]

Hilbert spaces provide one candidate for a weak formulation of a partial differential equation.[17]
For example, the Poisson equation −Δu = g with Dirichlet boundary conditions in a bounded domain Ω in R2 has weak formulation to find a function u such that, for all continuously differentiable functions v in Ω vanishing on the boundary:
This can be recast in terms of the Hilbert space  consisting of functions u such that u, along with its weak partial derivatives, are in L2(Ω), and which vanish on the boundary. The question then reduces to finding u in this space such that for all v in this space
where a is a continuous bilinear form, and b is a continuous linear functional, given respectively by
Since the Poisson equation is elliptic, it follows from Poincaré's inequality that the bilinear form a is coercive. The Lax-Milgram theorem is a geometrical result on Hilbert spaces that ensures the existence and uniqueness of solutions of this equation.
This procedure forms the rudiment of the Galerkin method (a finite element method) for numerical solution of PDEs.[18]

Applications to the field of ergodic theory include the von Neumann mean ergodic theorem.[19] If a dynamical system in a Hilbert space evolves according to unitary transformation, then the mean ergodic theorem says that the long-time average behavior of the system is stable under the process.
A physical consequence of the theorem is the following.[20] Let the function ƒ represent the value of a particular physical experiment on a phase space. Let Pτ be the true state of a mechanical system at time τ. By virtue of Liouville's theorem, the volume form on the phase space is preserved under the flows of P. In actual measurements, the value of ƒ itself is not computed, but rather its temporal means
The theorem ensures that, for long enough time averages, there is a constant around which the dispersion of the time average of ƒ(P) is small.

Applications include:[citation needed]
One goal of Fourier analysis is to write a given function as a (possibly infinite) linear combination of given basis functions. This problem can be studied abstractly in Hilbert spaces: every Hilbert space has an orthonormal basis, and every element of the Hilbert space can be written in a unique way as a sum of multiples of these basis elements. The Fourier transform then corresponds to a change of basis.[citation needed]

A Hilbert space is a real or complex inner product space that is complete under the norm defined by the inner product  by[21]
Some authors use slightly different definitions. For example, Kolmogorov and Fomin[22] define a Hilbert space as above but restrict the definition to infinite-dimensional spaces. Silverman, the translator of the book, restricts it even further to separable spaces. A separable, infinite-dimensional Hilbert space is unique up to isomorphism; it is denoted by ℓ2(N), or simply ℓ2, as it can be represented by the Lp space ℓ2. Older books and papers sometimes call a Hilbert space a unitary space or a linear space with an inner product, but this terminology has fallen out of use.
In the examples of Hilbert spaces given below, the underlying field of scalars is the complex numbers C, although similar definitions apply to the case in which the underlying field of scalars is the real numbers R.

Every finite-dimensional inner product space is also a Hilbert space. For example, Cn with the inner product defined by
where the bar over a complex number denotes its complex conjugate.

Given a set B, the sequence space  (commonly pronounced "little ell two") over B is defined by
This space becomes a Hilbert space with the inner product
for all x and y in . B does not have to be a countable set in this definition, although if B is not countable, the resulting Hilbert space is not separable. Every Hilbert space is isomorphic to one of the form  for a suitable set B. If B=N, the natural numbers, this space is separable and is simply called .

Lebesgue spaces are function spaces associated to measure spaces (X, M, μ), where X is a set, M is a σ-algebra of subsets of X, and μ is a countably additive measure on M. For example, Let L2μ(X) be the space of those complex-valued measurable functions on X for which the Lebesgue integral of the square of the absolute value of the function is finite, and where functions are identified if and only if they differ only on a set of measure 0.
The inner product of functions f and g in L2μ(X) is then defined as
This integral exists, and the resulting space is complete.[23] The full Lebesgue integral is needed to ensure completeness, however, as not enough functions are Riemann integrable.[24]


