Deinterlacing
Deinterlacing is the process of converting interlaced video, like common analog television signals, into a non-interlaced form.

Video and Film consist of a series of images played in rapid succession. Each of these images is known as a frame. Unlike a film frame, which is a single entity, a video frame is composed of multiple scan lines.
All mainstream analog television systems and many digital systems arrange scan lines of one frame into two fields. One field contains all even lines, another field contains all odd lines. The fields are then displayed in succession with a rate twice faster than the nominal frame rate. For instance, PAL and SECAM systems have rate of 25 frames/s or 50 fields/s, while the NTSC system delivers the rate of 30 frames/s or 60 fields/s. The process of producing half-resolution fields at double the frame rate is known as interlacing.
In footage shot by most television and video cameras (except more recent models which allow a non-interlaced mode), the two fields of a frame are taken at different times, which results in an effectively doubled time resolution as compared with non-interlaced footage, thus enhancing motion perception to the viewer. This remains one of the benefits of interlacing.
However its benefits can only be experienced if the display shows the individual fields in the same timely order they were shot in. At this time, only traditional CRT-based TV set are capable to do so. If correctly adjusted, they need not suffer from any interlacing artifacts, they even benefit from it.
Yet when the fields of the original footage are displayed in a different order than they were shot in (i.e. when two fields taken at different points in time are re-combined to a full frame displayed at once), visual defects called interlace artifacts or combing occur with moving objects in the image.
This is true for most modern LCD and plasma displays, because they are currently not able to work in interlaced mode. The problem only exists with SD television and interlaced HDTV, and there only with material shot with a tv or video camera, not with movies. Progressive HDTV video consists of full frames and does not exhibit interlace artifacts. Also computer displays don't suffer from it as their image isn't interlaced to begin with.
To combat interlace artifacts, all LCD and plasma consumer television sets have built-in circuitry that converts interlaced video into progressive video.
The process of converting interlaced video into progressive is called de-interlacing. If done poorly, de-interlacing can introduce image degradation.

In a typical CRT television, the interlaced display draws only half of the lines on the screen for each frame, alternately drawing the odd and even lines for each frame. This reduces flicker by taking advantage of the persistence of vision effect, producing a refresh rate of double the frame rate without the overhead of either transmitting each frame twice or holding it in a buffer so it can be redrawn.
When displaying video on a display that can support a high enough refresh rate such that flicker isn't perceivable, interlaced video can be deinterlaced for better viewing; likewise when a display cannot interlace but must draw the entire screen each time, the video must be deinterlaced before it can be displayed. All current displays except for CRT screens require deinterlacing. Though in principle there is no reason why LCD, DLP or Plasma displays should not display two fields sequentially, the requirement that half of the pixels remain black would result in a halving of brightness, even assuming that the response time of the technology could be made fast enough.
Deinterlacing requires the display to buffer one or more fields and recombine them into a single frame. In theory this would be as simple as capturing one field and combining it with the next field to be received, producing a single frame. However the originally recorded signal was produced as a series of fields, and any motion of the subjects during the short period between the fields is encoded into the display. When combined into a single frame, the slight differences between the two fields due to this motion results in a "tearing" effect where alternate lines are slightly displaced from each other.
Modern deinterlacing systems therefore buffer several fields and use techniques like edge detection in an attempt to find the motion between the fields. This is then used to interpolate the missing lines from the original field, reducing the "tearing" effects.[1]

There are various methods to deinterlace video, each producing different problems or artifacts of their own. Some methods are much cleaner in artifacts than other methods. All are indeed not equal.
Most de-interlacing techniques can be broken up into three different groups all using their own exact techniques. The first group are called Field Combination De-interlacers, because they take the even and odd fields and combine them into one image or frame which is then displayed. The second group are called Field Extension De-interlacers because each field (with only half the lines) is extended to the entire screen to make a frame. The third type use a combination of both and fall under the banner of Motion Compensation and a number of other names.



The best deinterlacers combine all of the methods mentioned above, both field combination and frame extension. This technique is often called motion compensation. Deinterlacers that use this technique are often superior because they can use information from many fields, as opposed to just one or two. For example, if two fields had a person's head moving to the left, then if weaving was applied, mouse teeth would appear. If blending was applied, ghosting would appear. Selective blending would also create ghosting. Both of the frame extension methods would have no artifacts and would be the best selection for this motion section of the scene. Advanced motion compensation (ideally) would in addition see that the face in both fields is the same, just transposed, and would combine the face (i.e. through image stacking) to get full detail in both output frames. Doublers as above don't provide combined field resolution in this form. This technology would need to be combined with a scene change detection algorithm, otherwise it will attempt to find motion between two completely different scenes. In the areas that it cannot find a motion match, it could fall back on selective blending. If frame rate was to be preserved it could fall back on doubling.
The best de-interlacers, (In the case of NTSC) also determine whether video material source was from film by checking for a 3:2 pulldown Telecine sequence. They automatically do a reverse telecine instead of the above deinterlacing techniques in this case. This operation is more automatic on modern deinterlacers than it used to be.

The European Broadcasting Union has argued against the use of interlaced video in production, recommending the use of 1080p/50 frame/s (frames per second) as a future production standard for easier conversion to other formats.[2]
Televisions and monitors are now more flexible at displaying different video formats than they were in the past. Most movies on Blu-ray discs have preserved the original non interlaced 24 frame/s motion film rate and allow output in this non-interlaced format directly to display devices, with no conversion necessary. At present (2008), Blu-ray does not support 1080p at 50frame/s, but does support 720p at 50frame/s and all interlaced formats.
Some 1080i HDV camcorders offer progressive mode with cinema-like frame rates of 24 or 25 frame/s, using techniques similar to the traditional telecine technique in NTSC countries and the 25 frame/s in PAL countries. Progressive frames are packaged within the interlaced signal and can be reproduced by standard consumer television equipment.
Deinterlacing is often called line doubling in many cases. There is confusion when this is referred to as interpolation, which uses spatial filtering to generate extra lines and hence reduce the visibility of pixelation on any type of display.[3] The terminology 'line doubler' is used more frequently in high end consumer electronics, while 'deinterlacing' is used more frequently in the computer and digital video arena. However, both are essentially the same thing in most cases.

Deinterlacing can be done at various points in the chain from filming to watching. The stage at which it is done can affect the quality of the conversion, because the quality of the deinterlacer can vary.



