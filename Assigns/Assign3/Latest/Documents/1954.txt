Frame rate
Frame rate, or frame frequency, is the measurement of the frequency (rate) at which an imaging device produces unique consecutive images called frames. The term applies equally well to computer graphics, video cameras, film cameras, and motion capture systems. Frame rate is most often expressed in frames per second (FPS) and in progressive-scan monitors as hertz (Hz).

There are three main frame rate standards in the TV and movie-making business.

Frame rate is also a term used in real-time computer graphics systems. In a fashion somewhat comparable to the moving-picture definition presented above, a real-time frame is the time it takes to complete a full round of the system's processing tasks. If the frame rate of a real-time system is 60 Hertz, the system reevaluates all necessary inputs and updates the necessary outputs 60 times per second under all circumstances.
The designed frame rates of real-time systems vary depending on the equipment. For a real-time system that is steering an oil tanker, a frame rate of 1 Hz may be sufficient, while a rate of even 100 Hz may not be adequate for steering a guided missile. The designer must choose a frame rate appropriate to the application's requirements.

Frame rates are considered important in video games. The frame rate can make the difference between a game that is playable and one that is not. The first 3D first-person adventure game for a personal computer, 3D Monster Maze, had a frame rate of approximately 6 frame/s, and was still a success. In modern action-oriented games where players must visually track animated objects and react quickly, frame rates of between 30 to 60 frame/s are considered minimally acceptable by some, though this can vary significantly from game to game. Most modern action games, including popular first person shooters such as Halo 3, run around 30 frames a second, while others, such as Call of Duty 4: Modern Warfare, run at 60 frames a second. The framerate within games, particularly PC games, typically varies, depending upon what is currently happening in the game. When the production of a frame makes large demands on the CPU and / or GPU, the framerate falls.
A culture of competition has arisen among game enthusiasts with regards to frame rates, with players striving to obtain the highest frame/s count possible. Indeed, many benchmarks (such as 3DMark) released by the marketing departments of hardware manufacturers and published in hardware reviews focus on the frame/s measurement. Modern video cards, often featuring NVIDIA or ATI chipsets, can perform at over 160 frame/s on graphics intensive games such as F.E.A.R. One single GeForce 8800 GTX has been reported to play F.E.A.R. at up to 386 frame/s (at a low resolution).[citation needed] This does not apply to all games: some games apply a limit on the frame rate. For example, in the Grand Theft Auto series, Grand Theft Auto III and Grand Theft Auto: Vice City have a standard 30 frame/s (Grand Theft Auto: San Andreas runs at 25 frame/s) and this limit can only be removed at the cost of graphical and gameplay stability. It is also doubtful whether striving for such high frame rates is worthwhile. An average 17" monitor can reach 60 Hz, meaning that any performance reached by the game over 60 frame/s is discarded. For that reason it is not uncommon to limit the frame rate to the refresh rate of the monitor in a process called vertical synchronization. However, many players feel that not synchronizing every frame produces sufficiently better game execution to justify some "tearing" of the images.
This choppiness is not a perceived flicker, but a perceived gap between the object in motion and its afterimage left in the eye from the last frame. A computer samples one point in time, then nothing is sampled until the next frame is rendered, so a visible gap can be seen between the moving object and its afterimage in the eye. The reason computer rendered video has a noticeable afterimage separation problem and camera captured video does not is that a camera shutter interrupts the light two or three times for every film frame, thus exposing the film to 2 or 3 samples at different points in time. The light can also enter for the entire time the shutter is open, thus exposing the film to a continuous sample over this time. These multiple samples are naturally interpolated together on the same frame. This leads to a small amount of motion blur between one frame and the next which allows them to transition smoothly.
An example of afterimage separation can be seen when taking a quick 180 degree turn in a game in only 1 second. A still object in the game would render 60 times evenly on that 180 degree arc (at 60 Hz frame rate), and visibly this would separate the object and its afterimage by 3 degrees. A small object and its afterimage 3 degrees apart are quite noticeably separated on screen.
The solution to this problem would be to interpolate the extra frames together in the back-buffer (field multisampling), or simulate the motion blur seen by the human eye in the rendering engine. When vertical sync is enabled, video cards only output a maximum frame rate equal to the refresh rate of the monitor. All extra frames are dropped. When vertical sync is disabled, the video card is free to render frames as fast as it can, but the display of those rendered frames is still limited to the refresh rate of the monitor. For example, a card may render a game at 100 FPS on a monitor running 75 Hz refresh, but no more than 75 FPS can actually be displayed on screen.
Certain elements of a game may be more GPU-intensive than others. While a game may achieve a fairly consistent 60 frame/s, the frame rate may drop below that during intensive scenes. By achieving frame rates in excess of what is displayable, it makes it less likely that frame rates will drop below what is displayable during heavy CPU/GPU load.

Even though computers, video and film works on distinct frames, sampled at discrete points in time, there is no evidence suggesting that the human visual system works in the same way. Therefore, it is impossible to express the limitations of human perception as a given maximum framerate.
It may be possible, however, to investigate the consequences of changes in framerate for human observers. The most famous example may be the wagon-wheel effect, a form of Aliasing in time, where a spinning wheel suddenly appears to change direction when its speed approaches the framerate of the image capture/reproduction system.
Different capture/playback systems may operate at the same framerate, and still give a different level of "realism" or artefacts attributed to framerate. One reason for this may be the temporal characteristics of the camera and display device.



