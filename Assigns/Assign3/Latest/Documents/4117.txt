Prime number theorem
In number theory, the prime number theorem (PNT) describes the asymptotic distribution of the prime numbers. The prime number theorem gives a rough description of how the primes are distributed.
Roughly speaking, the prime number theorem states that if you randomly select a number nearby some large number N, the chance of it being prime is about 1 / ln(N), where ln(N) denotes the natural logarithm of N. For example, near N = 10,000, about one in nine numbers is prime, whereas near N = 1,000,000,000, only one in every 21 numbers is prime. In other words, the average gap between prime numbers near N is roughly ln(N).[1]

Let Ï€(x) be the prime-counting function that gives the number of primes less than or equal to x, for any real number x. For example, Ï€(10) = 4 because there are four prime numbers (2, 3, 5 and 7) less than or equal to 10. The prime number theorem then states that the limit of the quotient of the two functions Ï€(x) and x / ln(x) as x approaches infinity is 1, which is expressed by the formula
known as the asymptotic law of distribution of prime numbers. Using asymptotic notation this result can be restated as
This notation (and the theorem) does not say anything about the limit of the difference of the two functions as x approaches infinity. (Indeed, the behavior of this difference is very complicated and related to the Riemann hypothesis.) Instead, the theorem states that x/ln(x) approximates Ï€(x) in the sense that the relative error of this approximation approaches 0 as x approaches infinity.
The prime number theorem is equivalent to the statement that the nth prime number pn is approximately equal to n ln(n), again with the relative error of this approximation approaching 0 as n approaches infinity.

Based on the tables by Anton Felkel and Jurij Vega, Adrien-Marie Legendre conjectured in 1796 that Ï€(x) is approximated by the function x/(ln(x)-B), where B=1.08... is a constant close to 1. Carl Friedrich Gauss considered the same question and, based on the computational evidence available to him and on some heuristic reasoning, he came up with his own approximating function, the logarithmic integral li(x), although he did not publish his results. Both Legendre's and Gauss's formulas imply the same conjectured asymptotic equivalence of Ï€(x) and x / ln(x) stated above, although it turned out that Gauss's approximation is considerably better if one considers the differences instead of quotients.
In two papers from 1848 and 1850, the Russian mathematician Pafnuty L'vovich Chebyshev attempted to prove the asymptotic law of distribution of prime numbers. His work is notable for the use of the zeta function Î¶(s) predating Riemann's celebrated memoir of 1859, and he succeeded in proving a slightly weaker form of the asymptotic law, namely, that if the limit of Ï€(x)/(x/ln(x)) as x goes to infinity exists at all, then it is necessarily equal to one. He was able to prove unconditionally that this ratio is bounded above and below by two explicitly given constants near to 1 for all x. Although Chebyshev's paper did not quite prove the Prime Number Theorem, he used his estimates for Ï€(x) to prove Bertrand's postulate that there exists a prime number between n and 2n for any integer n â‰¥ 2.
Without doubt, the single most significant paper concerning the distribution of prime numbers was Riemann's 1859 memoir On the Number of Primes Less Than a Given Magnitude, the only paper he ever wrote on the subject. Riemann introduced revolutionary ideas into the subject, the chief of them being that the distribution of prime numbers is intimately connected with the zeros of the analytically extended Riemann zeta function of a complex variable. In particular, it is in this paper of Riemann that the idea to apply methods of complex analysis to the study of the real function Ï€(x) originates. Extending these deep ideas of Riemann, two proofs of the asymptotic law of the distribution of prime numbers were obtained independently by Hadamard and de la VallÃ©e Poussin and appeared in the same year (1896). Both proofs used methods from complex analysis, establishing as a main step of the proof that the Riemann zeta function Î¶(s) is non-zero for all complex values of the variable s that have the form s = 1 + it with t > 0.[2]
During the 20th century, the theorem of Hadamard and de la VallÃ©e-Poussin also became known as the Prime Number Theorem. Several different proofs of it were found, including the "elementary" proofs of Atle Selberg and Paul ErdÅ‘s (1949).

In a lecture on prime numbers for a general audience, Fields medalist Terence Tao described one approach to proving the prime number theorem in poetic terms: listening to the "music" of the primes. We start with a "sound wave" that is "noisy" at the prime numbers and silent at other numbers; this is the von Mangoldt function. Then we analyze its notes or frequencies by subjecting it to a process akin to Fourier transform; this is the Mellin transform. Then we prove, and this is the hard part, that certain "notes" cannot occur in this music. This exclusion of certain notes leads to the statement of the prime number theorem. According to Tao, this proof yields much deeper insights into the distribution of the primes than the "elementary" proofs discussed below.[3]

Carl Friedrich Gauss conjectured that an even better approximation to Ï€(x) is given by the offset logarithmic integral function Li(x), defined by
Indeed, this integral is strongly suggestive of the notion that the 'density' of primes around t should be 1/lnt. This function is related to the logarithm by the asymptotic expansion
So, the prime number theorem can also be written as Ï€(x) ~ Li(x). In fact, it follows from the proof of Hadamard and de la VallÃ©e Poussin that
for some positive constant a, where O(â€¦) is the big O notation. This has been improved to
Because of the connection between the Riemann zeta function and Ï€(x), the Riemann hypothesis has considerable importance in number theory: if established, it would yield a far better estimate of the error involved in the prime number theorem than is available today. More specifically, Helge von Koch showed in 1901[4] that, if and only if the Riemann hypothesis is true, the error term in the above relation can be improved to
The constant involved in the big O notation was estimated in 1976 by Lowell Schoenfeld:[5] assuming the Riemann hypothesis,
for all x â‰¥ 2657. He also derived a similar bound for the Chebyshev prime-counting function Ïˆ:
for all x â‰¥ 73.2.
The logarithmic integral Li(x) is larger than Ï€(x) for "small" values of x. This is because it is (in some sense) counting not primes, but prime powers, where a power pn of a prime p is counted as 1/n of a prime. This suggests that Li(x) should usually be larger than Ï€(x) by roughly Li(x1/2)/2, and in particular should usually be larger than Ï€(x). However, in 1914, J. E. Littlewood proved that this is not always the case. The first value of x where Ï€(x) exceeds Li(x) is probably around x = 10316; see the article on Skewes' number for more details.

In the first half of the twentieth century, some mathematicians felt that there exists a hierarchy of techniques in mathematics, and that the prime number theorem is a "deep" theorem, whose proof requires complex analysis. Methods with only real variables were supposed to be inadequate. G. H. Hardy was one notable member of this group.[6]
The formulation of this belief was somewhat shaken by a proof of the prime number theorem based on Wiener's tauberian theorem, though this could be circumvented by awarding Wiener's theorem "depth" itself equivalent to the complex methods. The notion of "elementary proof" in number theory is not usually defined precisely, but it usually seems to correspond roughly to proofs that can be carried out in Peano arithmetic, rather than more powerful theories, such as second order arithmetic. There are statements of Peano arithmetic that can be proved in second order arithmetic but not first order arithmetic (see the Paris-Harrington theorem for an example), but they seem in practice to be rare. However, Atle Selberg found an elementary proof of the prime number theorem in 1949, which uses only number-theoretic means. (Paul ErdÅ‘s used Selberg's ideas to produce a slightly different elementary proof at about the same time.) Selberg's work effectively laid rest to the whole concept of "depth" for the prime number theorem, showing that technically "elementary" methods (in other words Peano arithmetic) were sharper than previously expected. In 2001 Sudac showed that the prime number theorem can even be proved in primitive recursive arithmetic[7], a much weaker theory than Peano arithmetic.
Avigad et al. wrote a computer verified version of Selberg's elementary proof in the Isabelle theorem prover in 2005.[8]
Dorian Goldfeld wrote a paper[6] detailing the history of the elementary proof, including a study of the ErdÅ‘sâ€“Selberg priority dispute over who first gave an elementary proof.

Let Ï€n,a(x) denote the number of primes in the arithmetic progression a, a + n, a + 2n, a + 3n, â€¦ less than x. Dirichlet and Legendre conjectured, and VallÃ©e Poussin proved, that, if a and n are coprime, then
where Ï†(Â·) is the Euler's totient function. In other words, the primes are distributed evenly among the residue classes [a] modulo n with gcd(a, n) = 1. This can be proved using similar methods used by Newman for his proof of the prime number theorem.[9]
Although we have in particular
empirically the primes congruent to 3 are more numerous and are nearly always ahead in this "prime number race"; the first reversal occurs at x = 26,861. [10] :1â€“2 However Littlewood showed in 1914 [10]:2 that there are infinitely many sign changes for the function
so the lead in the race switches back and forth infinitely many times. The prime number race generalizes to other moduli and is the subject of much research; Granville and Martin give a very thorough exposition and survey. [10]

The prime number theorem is an asymptotic result. Hence, it cannot be used to bound Ï€(x).
However, some bounds on Ï€(x) are known, for instance Pierre Dusart's
The first inequality holds for all x â‰¥ 599 and the second one for x â‰¥ 355991[11].
A weaker but sometimes useful bound is
for x â‰¥ 55[12]. In Dusart's thesis you also find slightly stronger versions of this type of inequality (valid for larger x.)

As a consequence of the prime number theorem, one gets an asymptotic expression for the nth prime number, denoted by pn:
A better approximation is
Rosser's theorem states that pn is larger than n ln n. This can be improved by the following pair of bounds[14]:
The left inequality is due to Pierre Dusart[15] and is valid for n â‰¥ 2.

The table compares exact values of Ï€(x) to the two approximations x / ln x and li(x). The last column, x / Ï€(x), is the average prime gap below x.

There is an analogue of the prime number theorem that describes the "distribution" of irreducible polynomials over a finite field; the form it takes is strikingly similar to the case of the classical prime number theorem.
To state it precisely, let F = GF(q) be the finite field with q elements, for some fixed q, and let Nn be the number of monic irreducible polynomials over F whose degree is equal to n. That is, we are looking at polynomials with coefficients chosen from F, which cannot be written as products of polynomials of smaller degree. In this setting, these polynomials play the role of the prime numbers, since all other monic polynomials are built up of products of them. One can then prove that
If we make the substitution x = qn, then the right hand side is just
which makes the analogy clearer. Since there are precisely qn monic polynomials of degree n (including the reducible ones), this can be rephrased as follows: if you select a monic polynomial of degree n randomly, then the probability of it being irreducible is about 1/n.
One can even prove an analogue of the Riemann hypothesis, namely that
The proofs of these statements are far simpler than in the classical case. It involves a short combinatorial argument, summarised as follows. Every element of the degree n extension of F is a root of some irreducible polynomial whose degree d divides n; by counting these roots in two different ways one establishes that
where the sum is over all divisors d of n. MÃ¶bius inversion then yields
where Î¼(k) is the MÃ¶bius function. (This formula was known to Gauss.) The main term occurs for d = n, and it is not difficult to bound the remaining terms. The "Riemann hypothesis" statement depends on the fact that the largest proper divisor of n can be no larger than n/2.


