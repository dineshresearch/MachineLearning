Loudness war
The loudness war (or loudness race) is the music industry's tendency to record, produce, and broadcast music at progressively increasing levels of loudness to attempt to create a sound that stands out from others.
This phenomenon can be observed in many areas of the music industry, particularly broadcasting and albums released on CD and DVD. In the case of CDs, the war stems from artists' and producers' desires to create CDs that sound as loud as possible, or louder than CDs from competing artists or recording labels.[2]
However, as the maximum amplitude of a CD is at a fixed level, once that level has been reached, the overall loudness can only be increased by a combination of dynamic range compression and make-up gain. This is done by applying an increasingly high ratio of compression to the dynamic range of the recording and then increasing the gain of the recording until the peaks have reached maximum. Certain extreme uses of dynamic range compression can introduce distortion or clipping to the waveform of the recording.


When comparing two recordings with different levels, it is likely that the louder one will be regarded as sounding better.[3] This can be attributed to the way the human ear responds to different sound pressure levels: our ability to respond to sound frequencies changes according to differences in sound pressure level, or SPL; the more the SPL increases,[4] the greater the amount of low and high frequency content we perceive.[5] Music with higher levels is easily heard and understood in noisy environments such as a car, train, or busy city street. Higher levels can also result in subjectively better-sounding recordings on low-quality reproduction systems such as web audio formats, AM radio, mono television, and telephones.[citation needed] Due to competition for listeners between radio stations and competition for clients between recording studios, this results in a volume "arms race".[6] Furthermore, artists and A&R people are usually inclined to request that their mastered music releases match the loudness level of other current contemporary music releases of similar genres.[2]

This practice has been condemned by several recording industry professionals including mastering engineer Doug Sax,[2] Geoff Emerick[7][8] (noted for his work with The Beatles from Revolver to Abbey Road), Steve Hoffman, and many others, including music audiophiles and hi-fi enthusiasts. Musician Bob Dylan has also condemned the practice, saying, "You listen to these modern records, they're atrocious, they have sound all over them. There's no definition of nothing, no vocal, no nothing, just likeâ€”static."[8][9]
Jay Graydon puts it this way:
When music is broadcast by a radio station, the station will apply its own signal processing, which further reduces the dynamic range of the broadcast material to closely match levels of absolute amplitude, regardless of the original record loudness.[11]
Opponents have also called for immediate changes in the music industry regarding the level of loudness. In August 2006, the vice-president of A&R for One Haven Music, a Sony Music company, in an open letter decrying the loudness war, claimed that mastering engineers are being forced against their will or are preemptively making releases louder in order to get the attention of industry heads.[9] Some bands are being petitioned to re-release their music with less distortion.[8] This may indicate a general public discontent with this practice and a call to put an end to the loudness war.
Many bands have their records made louder against their will.[citation needed] Several organizations have been founded to attempt to put the choice back in the hands of the bands.[citation needed] The nonprofit organization Turn Me Up! has also been formed to encourage the sale of quieter records by placing a "Turn Me Up!" sticker on albums that have a larger dynamic range.[12]
Hearing experts, such as a hearing researcher at House Ear Institute in Los Angeles, are also concerned that the loudness of new albums could possibly harm listeners' hearing, particularly in children.[12]
A 2-minute YouTube video addressing this issue by audio engineer Matt Mayfield has been referenced by The Wall Street Journal[13] and The Chicago Tribune.[14]

The practice of increasing music release's loudness to be louder than competing releases can have two effects. Since there is a maximum loudness level available to recording (as opposed to playback, in which the loudness is limited by the playback speakers and amplifiers), boosting the overall loudness of a song or track eventually creates a piece that is maximally and uniformly loud from beginning to end. This creates music with a small dynamic range (i.e., little difference between loud and quiet sections), rendering it fatiguing and robbing it of emotional power, according to Robert Levine of Rolling Stone.[15]
The other possible effect is distortion. In the digital realm, this is usually referred to as clipping. Digital media cannot output signals higher than digital full scale (0 dBFS), so whenever the peak of a signal is pushed past this point, it results in the wave form becoming clipped. When this occurs, it can sometimes produce an audible click. However, certain sounds like drum hits will reach their peak for only a very short time, and if that peak is much louder than the rest of the signal, this click will be heard. In many cases, the peaks of drum hits are clipped but are not noticeable to the casual listener. However, if clipping occurs too much in a recording, it can make the recording sound distorted, a sound which some listeners find harsh and fatiguing to listen to. How much is too much is a matter of taste, but most pop and rock releases, and many jazz, have some amount of digital clipping.
Analog media, on the other hand, dynamically compress the signal as it exceeds its saturation point. Such distortion can be utilized in the digital realm as well, either by transferring audio processed with tape or valve saturation to a digital recording medium, or by using computer software to emulate the effect (this process is usually referred to as "saturation"). Analog distortion, real or emulated, results in harmonics that can appear to the listener as a slight "crackle" or "fuzz" within the sound. The effect can vary depending on the sound itself, as well as the amount and kind of distortion used. Because analog distortion does not flatline to the extent that digital clipping does, the results are less harsh-sounding and can result in a desirable warmth to the recording, at the cost of slightly less transient response. The amount of distortion increases the more a signal is overdriven, ranging from transparent to highly audible, and just like digital clipping, certain instruments or musical arrangements can better mask distortion than others[citation needed].
In other cases, compression or limiting is used. While the resulting distortion is lessened from the final product this way, it has the side effect of significantly reducing transient response (most often heard as lessened drum impact), and, when taken to severe levels, can reduce the natural dynamics of other instruments within the recording. Loudness increasing techniques, however, do not always affect macrodynamics (the difference in volume between sections of a song) if used with care and detail[citation needed]. Multi-band compression is commonly used to make a mix more uniform and easier to balance, more compatible with low-end equipment, or to achieve a certain sound or artistic effect[citation needed]. Dynamic range or broadcast-style compression, on the other hand, will be applied to the music to make the volume in different song sections more uniform.[15] This can make the recording more suitable for background listening or noisy environments but can also reduce the dynamic expressiveness of the song as a whole.

The practice of focusing on loudness in mastering can be traced back to the introduction of the compact disc itself but also existed to some extent when vinyl was the primary released recording medium and when 7" singles were played on jukebox machines in clubs and bars. Jukeboxes were often set to a pre-determined level by the bar owner, yet any record that was mastered "hotter" than the others before or after it would gain the attention of the crowd. The song would stand out. Also many record companies would print compilation records, and when artists and producers found their song was quieter than others on the compilation, they would insist that their song be remastered to be competitive. Also, many Motown records pushed the limits of how loud records could be made, and record labels there were "notorious for cutting some of the hottest 45s in the industry."[2] However, because of the limitations of the vinyl format, loudness and compression on a released recording were restricted in order to make the physical medium playableâ€”restrictions which do not exist on digital media such as CDsâ€”and as a result, increasing loudness levels never reached the significance that they have in the CD era.[9] In addition, modern computer-based digital audio effects processing allows mastering engineers to have greater control over the loudness of a song; for example, it gives them the ability to use a "brick wall" limiter which limits the volume level of an audio signal with no delay (hardware equivalents have a short delay due to processing time).[3]
The stages of the CDs loudness increase are often split over the two-and-a-half decades of the medium's existence. Since CDs were not the primary medium for popular music until the tail end of the 1980s, there was little motivation for competitive loudness practices then. CD players were also very expensive and thus commonly exclusive to high-end systems that would show the shortcomings of higher recording levels.
As a result, the common practice of mastering music involved matching the highest peak of a recording at, or close to, digital full scale, and referring to digital levels along the lines of more familiar analog VU meters. When using VU meters, a certain point (usually -14 dBFS, or about 20% of the disc's amplitude on a linear scale) was used in the same way as the saturation point (signified as 0 dB) of analog recording, with several dB of the CD's recording level reserved for amplitude exceeding the saturation point (often referred to as the "red zone", signified by a red bar in the meter display), because digital media cannot exceed 0 dB. The average level of the average rock song during most of the decade was around -18 dBFS[citation needed].
At the turn of the decade, CDs with music louder than this level began to surface, and CD volumes became more and more likely to exceed the digital limit as long as such amplification would not involve clipping more than approximately two to four digital samples, resulting in recordings where the peaks on an average rock or beat-heavy pop CD hovered near (usually in the range of -3 dB) 0 dB but only occasionally reached it. The Guns N' Roses album Appetite for Destruction from 1987 is an early example of this, with levels averaging -15 dB for all the tracks.[16]
In the early 1990s, some mastering engineers decided to take this a step further and treat the music's levels exactly as they would the levels of an analog tape and equate digital full scale with the analog saturation point, with the recording just loud enough so that each (or almost every) beat would peak at or close to 0 dBFS. Though there were some early cases (such as Metallica's Black Album in 1991), albums mastered in this fashion generally did not appear until 1992. Dirt by Alice In Chains and Faith No More's Angel Dust are some examples from this year. The loudness of releases during this period varied greatly depending on the philosophies of the engineer and others involved in the mastering process. This style of "hot" mastering became commonplace in 1994, though exceptions, such as the album Superunknown by Soundgarden from the same year, still existed. The most common loudness for a rock release in terms of average power was around -12 dBFS. Overall, most rock and pop music released in the 1990s followed this method to a certain extent[citation needed].
The concept of making music releases "hotter" began to appeal to people within the industry, due in part to how noticeably louder releases had become and also in part to the notion that customers preferred louder sounding CDs.[citation needed] Engineers, musicians and labels each developed their own ideas of how CDs could be made louder[citation needed]. In 1994, the digital brickwall limiter with look-ahead (to pull down peak levels before they happened) was first mass-produced. While the increase in CD loudness was gradual throughout the 1990s, some opted to push the format to the limit, such as on Oasis' widely popular album (What's the Story) Morning Glory?, which averaged -8 dBFS on many of its tracks[16]â€”a rare occurrence, especially in the year it was released (1995). In 1997, Iggy Pop assisted in the remix and remaster of the 1973 album Raw Power by his former band The Stooges, creating an album that, to this day, is arguably the loudest rock CD ever recorded. It has an average of -4 dBFS in places,[16] which is rare even by today's standards[citation needed], though getting more and more common.
The standards of loudness would reach their limit in the 2000s. -10 dB had been the standard for the past several years, but this was often pushed to -9 dB. However, -6 to -5 dBFS is common in rock, contemporary R&B, pop, and hip hop music. Quieter exceptions to today's standards are rare. The latest releases as of 2008 have reached average levels as high as -3 dBFS, such as Angels & Airwaves' I-Empire, which yields almost 30 times the loudness of a THX standard recording (-20 dBFS).
The loudness war achieved significant mainstream media attention in 2008 following the controversy surrounding Metallica's latest album, Death Magnetic. As well as having a very high average loudness, the album's audio is heavily distorted and digitally clipped, and suffered an unprecedented amount of criticism as a result. An online petition calling for the album to be remixed or remastered[17] gained thousands of votes (over 19000 as of 2009-01-09) and the issue has been widely covered by, amongst others, Rolling Stone Magazine,[18] The Wall Street Journal,[19] BBC Radio,[20] Wired Magazine[21] and The Guardian newspaper.[22] The album's mastering engineer Ted Jensen unwittingly contributed to the controversy when his comments from a private e-mail were quoted (without his permission) by a fan on the MetallicaBB forums. Further ammunition for the campaign was indirectly provided by the existence of an alternative version of the release, as downloadable content for the video game Guitar Hero III, which fans claim sounds better since it doesn't suffer from the distortion of the CD version.[23]

Views regarding the effect of the loudness war are heavily subjective. Proponents of louder music releases claim that consumers prefer louder CDs (or other music format, such as Mp3s) and that they are better for most busy listening environments. Music media containing large amounts of clipping are thus played back at lower volume than non-clipped recordings due to the excessive harshness of the sound.[citation needed] Many hold the opinion that only a handful of albums, such as the Red Hot Chili Peppers' 1999 release Californication (an album with such excessive amounts of high-frequency digital clipping that audio enthusiasts have deemed it "unlistenable"), are examples worth considering, while others believe any CDs where digital full scale is utilized should be considered unacceptable.[24] Such listeners may be unwilling to listen to albums mastered in a loudness-based fashion. Conversely, others may not notice the effects at all or consider them only a minor annoyance. Likewise, many mastering engineers believe a loudness standard should be implemented. These proposals vary with individuals, but common proposed levels vary between the THX standard (-20 dBfs) for movies and the level commonly possible without clipping when mastering from a hot 1/4" tape (-14 dBfs).

Many recordings have been re-released in remastered form. The critical response to remasters can be mixed. Sometimes an extended frequency response is welcomed, since this can improve the sense of clarity and ambience of the recording. Other times, this improved sense of ambience may be counterbalanced by an unnatural and excessive sharpness to the recording.[25]
Many record companies may decide to increase the average level of the recording with the aid of compression, limiting, and/or clipping. This is especially common with pop music remasters. Two screenshots here, of ABBA's "One of Us," from its 1981 album The Visitors (released on CD in 1983), demonstrate the effect.
The first image is taken from the original Polydor/PolyGram Records CD release.
The second image is taken from the 2005 remaster (part of the Complete Studio Recordings box set, not to be confused with the 2001 remaster by Polydor/Universal Records). There is a heavy amount of compression, and the dynamics and snap of the original track have been lost as a result.
The Examples section contains several other remastered albums that have been remastered in this fashion.

At present, the loudness war tends to affect mostly audio CDs and consequently any MP3 or other copies produced from them.
Some recent recordings released on vinyl do not undergo the same kind of loudness-based mastering, although many still do. This is partly due to technical limitations of the format and partly due to vinyl now being a product for the niche market favoured by a small number of hi-fi enthusiastsâ€”similar to the CD's role in the mid-1980s.
Some SACD and DVD-Audio releases are affected as well. However, nearly all DVD-Audio discs also contain a Dolby Digital (AC3) or DTS sound track to allow the disc to be played in DVD-Video players without DVD-Audio playback capability. Dolby Digital has a defined and calibrated reference average playback level (-20 dBFS), and the DTS track will also follow this level. It is therefore beneficial that the high-resolution DVD-Audio soundtrack will be produced at the same reference levelâ€”and this indeed is normally the case.
As these new high-resolution formats are marketed largely at audiophiles, attempts to master them for loudness would almost certainly be counterproductive, as the target audience is likely to be highly critical of sound quality and dynamics.

